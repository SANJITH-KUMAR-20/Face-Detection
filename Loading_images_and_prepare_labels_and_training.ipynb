{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byte_to_img(x):\n",
    "    byteimg = tf.io.read_file(x)\n",
    "    return tf.io.decode_jpeg(byteimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.data.Dataset.list_files(\"augm_data\\\\Train\\\\images\\\\*.jpg\",shuffle = False)\n",
    "train_images = train_images.map(byte_to_img)\n",
    "train_images = train_images.map(lambda x: tf.image.resize(x,(120,120)))\n",
    "train_images = train_images.map(lambda x: x/255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = tf.data.Dataset.list_files(\"augm_data\\\\Test\\\\images\\\\*.jpg\",shuffle = False)\n",
    "test_images = test_images.map(byte_to_img)\n",
    "test_images = test_images.map(lambda x: tf.image.resize(x,(120,120)))\n",
    "test_images = test_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_images = tf.data.Dataset.list_files(\"augm_data\\\\Val\\\\images\\\\*.jpg\",shuffle = False)\n",
    "valid_images = valid_images.map(byte_to_img)\n",
    "valid_images = valid_images.map(lambda x: tf.image.resize(x,(120,120)))\n",
    "valid_images = valid_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path):\n",
    "    with open(label_path.numpy(),'r',encoding = 'utf-8') as f:\n",
    "        label = json.load(f)\n",
    "    return [label['class']],label['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.data.Dataset.list_files('augm_data\\\\Train\\\\labels\\\\*.json', shuffle=False)\n",
    "train_labels = train_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = tf.data.Dataset.list_files('augm_data\\\\Test\\\\labels\\\\*.json', shuffle=False)\n",
    "test_labels = test_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = tf.data.Dataset.list_files('augm_data\\\\Val\\\\labels\\\\*.json', shuffle=False)\n",
    "val_labels = val_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_images),len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.zip((train_images,train_labels))\n",
    "train = train.shuffle(7000)\n",
    "train = train.batch(8)\n",
    "train = train.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.zip((test_images,test_labels))\n",
    "test = test.shuffle(7000)\n",
    "test = test.batch(8)\n",
    "test = test.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = tf.data.Dataset.zip((valid_images,val_labels))\n",
    "val = val.shuffle(7000)\n",
    "val = val.batch(8)\n",
    "val = val.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.as_numpy_iterator().next()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samples = train.as_numpy_iterator().next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4): \n",
    "    sample_image = data_samples[0][idx]\n",
    "    sample_coords = data_samples[1][1][idx]\n",
    "    \n",
    "    cv.rectangle(sample_image, \n",
    "                  tuple(np.multiply(sample_coords[:2], [120,120]).astype(int)),\n",
    "                  tuple(np.multiply(sample_coords[2:], [120,120]).astype(int)), \n",
    "                        (255,0,0), 2)\n",
    "\n",
    "    ax[idx].imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(include_top = False)\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model():\n",
    "    input_layer = tf.keras.layers.Input(shape=(120,120,3))\n",
    "    vgg = VGG16(include_top = False)(input_layer)\n",
    "\n",
    "    f1 = tf.keras.layers.GlobalMaxPooling2D()(vgg)\n",
    "    class1 = tf.keras.layers.Dense(2048,activation='relu')(f1)\n",
    "    class2 = tf.keras.layers.Dense(1,activation='sigmoid')(class1)\n",
    "\n",
    "    func2 = tf.keras.layers.GlobalMaxPooling2D()(vgg)\n",
    "    regress1 = tf.keras.layers.Dense(2048,activation = 'relu')(func2)\n",
    "    regress2 = tf.keras.layers.Dense(4,activation='sigmoid')(regress1)\n",
    "\n",
    "    mymod = tf.keras.models.Model(inputs=input_layer,outputs = [class2,regress2])\n",
    "    return mymod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_per_epoch = len(train)\n",
    "lr_decay = (1.0/0.75-1)/batches_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_loss(y_true,y_pred):\n",
    "    delta_coord = tf.reduce_sum(tf.square(y_true[:,:2]-y_pred[:,:2]))\n",
    "\n",
    "    h_true = y_true[:,3] - y_true[:,1]\n",
    "    w_true = y_true[:,2] - y_true[:,0]\n",
    "\n",
    "    h_pred = y_pred[:,3] - y_pred[:,1]\n",
    "    w_pred = y_pred[:,2] - y_pred[:,0]\n",
    "\n",
    "    delta_size = tf.reduce_sum(tf.square(w_true-w_pred)+tf.square(h_true-h_pred)) \n",
    "    return delta_coord + delta_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.models.Model):\n",
    "    def __init__(self,modelx,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = modelx\n",
    "    \n",
    "    def compile(self,optimizer,classification_loss,locatization_loss,**kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.closs = classification_loss\n",
    "        self.lloss = localization_loss\n",
    "        self.opt = optimizer\n",
    "    \n",
    "    def train_step(self,batch,**kwargs):\n",
    "        x,y = batch\n",
    "        with tf.GradientTape() as tape:\n",
    "            classes,coordinates = self.model(x,training = True)\n",
    "\n",
    "            batch_classloss = self.closs(y[0],classes)\n",
    "            batch_localizationloss = self.lloss(tf.cast(y[1],tf.float32),coordinates)\n",
    "            total_loss = batch_localizationloss+0.5*batch_classloss\n",
    "\n",
    "            grad = tape.gradient(total_loss,self.model.trainable_variables)\n",
    "        self.opt.apply_gradients(zip(grad,self.model.trainable_variables))\n",
    "\n",
    "        return {\"total_loss\":total_loss,\"class_loss\":batch_classloss,\"regression_loss\":batch_localizationloss}\n",
    "    def test_step(self,batch,**kwargs):\n",
    "        x,y = batch\n",
    "\n",
    "        classes,coords = self.model(x,training = True)\n",
    "\n",
    "        batch_classloss = self.closs(y[0],classes)\n",
    "        batch_locatizationloss = self.lloss(tf.cast(y[1],tf.float32),coords)\n",
    "        total_loss = batch_locatizationloss + 0.5*batch_classloss\n",
    "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss,\"regress_loss\":batch_locatizationloss}\n",
    "    def call(self, x,**kwargs):\n",
    "        return self.model(x,**kwargs)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001,weight_decay=lr_decay),classification_loss=tf.keras.losses.BinaryCrossentropy(),locatization_loss=localization_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = 'logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = model.fit(train,epochs =20 , validation_data = val, callbacks = [tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.as_numpy_iterator()\n",
    "test_samples = test_data.next()\n",
    "predictions = model.predict(test_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(ncols = 4,figsize = (20,20))\n",
    "for i in range(4):\n",
    "    sample_img = test_samples[0][idx]\n",
    "    sample_coords = predictions[1][idx]\n",
    "\n",
    "    if predictions[0][idx]>0.5:\n",
    "        cv.rectangle(sample_img,tuple(np.multiply(sample_coords[:2],[120,120]).astype(int)),\n",
    "                     tuple(np.multiply(sample_coords[2:],[120,120]).astype(int)),\n",
    "                     (0,255,0),2)\n",
    "    ax[i].imshow(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
